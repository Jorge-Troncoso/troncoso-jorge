{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6840b5",
   "metadata": {},
   "source": [
    "# Actividad 1 No evaluada Exploración de datos en Python\n",
    "\n",
    "- **Profesor:** Francisco Perez Galarce\n",
    "- **Ayudante:** Yesenia Salinas\n",
    "\n",
    "**Integrante:**\n",
    "- Jorge Troncoso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf333f0",
   "metadata": {},
   "source": [
    "# Lectura y analisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7c2f4df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas de la base de datos:\n",
      "       ID        Nombre         2016          2017 Crecimiento Unidades  \\\n",
      "0   10002     Verde Mar  $125,000.00    $162500.00      30.00%      500   \n",
      "1  552278  Manantial sa  $920,000.00  $101,2000.00      10.00%      700   \n",
      "2   23477          ACME   $50,000.00      62500.00      25.00%      125   \n",
      "3   24900     Andes sur  $350,000.00     490000.00       4.00%       75   \n",
      "4  651029     San Pablo   $15,000.00     $12750.00     -15.00%       No   \n",
      "\n",
      "        fecha Activo  \n",
      "0   1-10-2015      1  \n",
      "1   6-23-2014      0  \n",
      "2   3-12-2016      1  \n",
      "3  10-28-2015      1  \n",
      "4   2-15-2014      0  \n",
      "\n",
      "Tipos de datos originales:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID           5 non-null      object\n",
      " 1   Nombre       5 non-null      object\n",
      " 2   2016         5 non-null      object\n",
      " 3   2017         5 non-null      object\n",
      " 4   Crecimiento  5 non-null      object\n",
      " 5   Unidades     5 non-null      object\n",
      " 6   fecha        5 non-null      object\n",
      " 7   Activo       5 non-null      object\n",
      "dtypes: object(8)\n",
      "memory usage: 452.0+ bytes\n",
      "None\n",
      "\n",
      "Valores nulos por columna:\n",
      "ID             0\n",
      "Nombre         0\n",
      "2016           0\n",
      "2017           0\n",
      "Crecimiento    0\n",
      "Unidades       0\n",
      "fecha          0\n",
      "Activo         0\n",
      "dtype: int64\n",
      "\n",
      "'ID' convertido exitosamente a entero.\n",
      "'Activo' convertido exitosamente a booleano.\n",
      "\n",
      "Tipos de datos después de las primeras transformaciones:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ID           5 non-null      int32 \n",
      " 1   Nombre       5 non-null      object\n",
      " 2   2016         5 non-null      object\n",
      " 3   2017         5 non-null      object\n",
      " 4   Crecimiento  5 non-null      object\n",
      " 5   Unidades     5 non-null      object\n",
      " 6   fecha        5 non-null      object\n",
      " 7   Activo       5 non-null      bool  \n",
      "dtypes: bool(1), int32(1), object(6)\n",
      "memory usage: 397.0+ bytes\n",
      "None\n",
      "\n",
      "'2016' limpiado y convertido exitosamente a flotante.\n",
      "'Unidades' limpiado y convertido exitosamente a entero.\n",
      "\n",
      "Tipos de datos después de la limpieza y conversiones:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ID           5 non-null      int32  \n",
      " 1   Nombre       5 non-null      object \n",
      " 2   2016         5 non-null      float64\n",
      " 3   2017         5 non-null      object \n",
      " 4   Crecimiento  5 non-null      object \n",
      " 5   Unidades     5 non-null      int32  \n",
      " 6   fecha        5 non-null      object \n",
      " 7   Activo       5 non-null      bool   \n",
      "dtypes: bool(1), float64(1), int32(2), object(4)\n",
      "memory usage: 377.0+ bytes\n",
      "None\n",
      "\n",
      "Datos después de la transformación:\n",
      "       ID        Nombre      2016          2017 Crecimiento  Unidades  \\\n",
      "0   10002     Verde Mar  125000.0    $162500.00      30.00%       500   \n",
      "1  552278  Manantial sa  920000.0  $101,2000.00      10.00%       700   \n",
      "2   23477          ACME   50000.0      62500.00      25.00%       125   \n",
      "3   24900     Andes sur  350000.0     490000.00       4.00%        75   \n",
      "4  651029     San Pablo   15000.0     $12750.00     -15.00%         0   \n",
      "\n",
      "        fecha  Activo  \n",
      "0   1-10-2015    True  \n",
      "1   6-23-2014    True  \n",
      "2   3-12-2016    True  \n",
      "3  10-28-2015    True  \n",
      "4   2-15-2014    True  \n",
      "\n",
      "Resumen estadístico de las variables numéricas:\n",
      "                  ID           2016    Unidades\n",
      "count       5.000000       5.000000    5.000000\n",
      "mean   252337.200000  292000.000000  280.000000\n",
      "std    320838.999788  374476.300986  303.829722\n",
      "min     10002.000000   15000.000000    0.000000\n",
      "25%     23477.000000   50000.000000   75.000000\n",
      "50%     24900.000000  125000.000000  125.000000\n",
      "75%    552278.000000  350000.000000  500.000000\n",
      "max    651029.000000  920000.000000  700.000000\n",
      "\n",
      "Valores únicos en la columna 'Activo':\n",
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Cargar la base de datos\n",
    "# Exploración de opciones del método pd.read_csv\n",
    "# Algunos argumentos útiles de pd.read_csv:\n",
    "# - sep: especifica el separador de columnas (por ejemplo, ',' o '\\t').\n",
    "# - header: especifica qué fila usar como encabezado (por defecto, la primera fila).\n",
    "# - na_values: define valores que se deben interpretar como NaN.\n",
    "# - dtype: permite definir tipos de datos iniciales por columna.\n",
    "# - parse_dates: convierte columnas a tipo datetime automáticamente.\n",
    "# - encoding: especifica la codificación del archivo (por ejemplo, 'utf-8' o 'latin-1').\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"ejemplo_data.csv\",  # Nombre del archivo\n",
    "    delimiter=\",\",       # Separador de columnas\n",
    "    encoding=\"utf-8\",    # Codificación del archivo\n",
    "    dtype=str            # Todas las columnas se cargan inicialmente como texto\n",
    ")\n",
    "\n",
    "# Mostrar las primeras filas para verificar la estructura de la base\n",
    "print(\"Primeras filas de la base de datos:\")\n",
    "print(data.head())\n",
    "\n",
    "# 2. Identificar los tipos de variables disponibles\n",
    "print(\"\\nTipos de datos originales:\")\n",
    "print(data.info())  # Muestra los tipos de datos y valores no nulos por columna\n",
    "\n",
    "# Verificar valores nulos por columna\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(data.isnull().sum())  # Muestra cuántos valores faltantes tiene cada columna\n",
    "\n",
    "# 3. Transformaciones de tipo\n",
    "# Convertir ID a entero\n",
    "if 'ID' in data.columns:\n",
    "    try:\n",
    "        data['ID'] = data['ID'].astype(int)\n",
    "        print(\"\\n'ID' convertido exitosamente a entero.\")\n",
    "    except ValueError:\n",
    "        print(\"\\nError: 'ID' contiene valores no convertibles a entero.\")\n",
    "\n",
    "# Convertir Activo a booleano\n",
    "if 'Activo' in data.columns:\n",
    "    try:\n",
    "        data['Activo'] = data['Activo'].astype(bool)\n",
    "        print(\"'Activo' convertido exitosamente a booleano.\")\n",
    "    except ValueError:\n",
    "        print(\"\\nError: 'Activo' contiene valores no convertibles a booleano.\")\n",
    "\n",
    "print(\"\\nTipos de datos después de las primeras transformaciones:\")\n",
    "print(data.info())\n",
    "\n",
    "# 4. Limpieza y conversión de columnas específicas\n",
    "# Limpiar y convertir 2016 a flotante\n",
    "if '2016' in data.columns:\n",
    "    try:\n",
    "        data['2016'] = data['2016'].str.replace(r'[\\$,]', '', regex=True).astype(float)\n",
    "        print(\"\\n'2016' limpiado y convertido exitosamente a flotante.\")\n",
    "    except ValueError:\n",
    "        print(\"\\nError: '2016' contiene valores no convertibles a flotante.\")\n",
    "\n",
    "# Limpiar y convertir Unidades a entero\n",
    "if 'Unidades' in data.columns:\n",
    "    try:\n",
    "        data['Unidades'] = pd.to_numeric(data['Unidades'], errors='coerce').fillna(0).astype(int)\n",
    "        print(\"'Unidades' limpiado y convertido exitosamente a entero.\")\n",
    "    except ValueError:\n",
    "        print(\"\\nError: 'Unidades' contiene valores no convertibles a entero.\")\n",
    "\n",
    "# Verificar tipos después de las conversiones\n",
    "print(\"\\nTipos de datos después de la limpieza y conversiones:\")\n",
    "print(data.info())\n",
    "\n",
    "# Mostrar las primeras filas después de la transformación\n",
    "print(\"\\nDatos después de la transformación:\")\n",
    "print(data.head())\n",
    "\n",
    "# 5. Resumen adicional de los datos\n",
    "# - Estadísticas descriptivas de variables numéricas\n",
    "print(\"\\nResumen estadístico de las variables numéricas:\")\n",
    "print(data.describe(include=[float, int]))\n",
    "\n",
    "# - Verificación de valores únicos en columnas clave\n",
    "if 'Activo' in data.columns:\n",
    "    print(\"\\nValores únicos en la columna 'Activo':\")\n",
    "    print(data['Activo'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191c9fd",
   "metadata": {},
   "source": [
    "# Lectura y analisis exploratorio de datos 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21cce09e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo cargado exitosamente con 'latin-1'.\n",
      "Primeras filas de la base de datos:\n",
      "  InvoiceNo StockCode                          Description Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER        6   \n",
      "1    536365     71053                  WHITE METAL LANTERN        6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER        8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE        6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.        6   \n",
      "\n",
      "      InvoiceDate UnitPrice CustomerID         Country  \n",
      "0  12/1/2010 8:26      2.55      17850  United Kingdom  \n",
      "1  12/1/2010 8:26      3.39      17850  United Kingdom  \n",
      "2  12/1/2010 8:26      2.75      17850  United Kingdom  \n",
      "3  12/1/2010 8:26      3.39      17850  United Kingdom  \n",
      "4  12/1/2010 8:26      3.39      17850  United Kingdom  \n",
      "\n",
      "Datos después de realizar un merge:\n",
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  UnitPrice CustomerID         Country InvoiceDate_Date  \\\n",
      "0 2010-12-01 08:26:00       2.55      17850  United Kingdom       2010-12-01   \n",
      "1 2010-12-01 08:26:00       3.39      17850  United Kingdom       2010-12-01   \n",
      "2 2010-12-01 08:26:00       2.75      17850  United Kingdom       2010-12-01   \n",
      "3 2010-12-01 08:26:00       3.39      17850  United Kingdom       2010-12-01   \n",
      "4 2010-12-01 08:26:00       3.39      17850  United Kingdom       2010-12-01   \n",
      "\n",
      "  InvoiceDate_Time  TotalAmount ExtraInfo  \n",
      "0         08:26:00        15.30       NaN  \n",
      "1         08:26:00        20.34       NaN  \n",
      "2         08:26:00        22.00       NaN  \n",
      "3         08:26:00        20.34       NaN  \n",
      "4         08:26:00        20.34       NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Cargar la base de datos\n",
    "try:\n",
    "    data = pd.read_csv(\n",
    "        \"ecommerce_data.csv\",  # Nombre del archivo\n",
    "        delimiter=\",\",         # Separador de columnas\n",
    "        encoding=\"latin-1\",    # Codificación alternativa\n",
    "        dtype=str              # Carga inicial de todas las columnas como texto\n",
    "    )\n",
    "    print(\"Archivo cargado exitosamente con 'latin-1'.\")\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"Error de codificación: {e}\")\n",
    "    print(\"Intentando cargar el archivo con 'ISO-8859-1'...\")\n",
    "    data = pd.read_csv(\n",
    "        \"ecommerce_data.csv\",\n",
    "        delimiter=\",\",\n",
    "        encoding=\"ISO-8859-1\",\n",
    "        dtype=str\n",
    "    )\n",
    "    print(\"Archivo cargado exitosamente con 'ISO-8859-1'.\")\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "print(\"Primeras filas de la base de datos:\")\n",
    "print(data.head())\n",
    "\n",
    "# Transformaciones de tipo\n",
    "if 'InvoiceNo' in data.columns:\n",
    "    data['InvoiceNo'] = data['InvoiceNo'].astype(str)  # Convertir a str\n",
    "if 'Description' in data.columns:\n",
    "    data['Description'] = data['Description'].astype(str)  # Convertir a str\n",
    "if 'Quantity' in data.columns:\n",
    "    data['Quantity'] = data['Quantity'].astype(int)  # Convertir a int\n",
    "if 'UnitPrice' in data.columns:\n",
    "    data['UnitPrice'] = data['UnitPrice'].astype(float)  # Convertir a float\n",
    "\n",
    "# Separar InvoiceDate\n",
    "if 'InvoiceDate' in data.columns:\n",
    "    data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
    "    data['InvoiceDate_Date'] = data['InvoiceDate'].dt.date\n",
    "    data['InvoiceDate_Time'] = data['InvoiceDate'].dt.time\n",
    "\n",
    "# Crear columna TotalAmount\n",
    "if 'Quantity' in data.columns and 'UnitPrice' in data.columns:\n",
    "    data['TotalAmount'] = data['Quantity'] * data['UnitPrice']\n",
    "\n",
    "# Exportar base procesada\n",
    "data.to_csv(\"ecommerce_data_processed.csv\", index=False)\n",
    "\n",
    "# Exploración avanzada\n",
    "grouped = data.groupby('InvoiceNo')['TotalAmount'].sum()\n",
    "sorted_data = data.sort_values(by='TotalAmount', ascending=False)\n",
    "indexed_data = data.set_index('InvoiceNo')\n",
    "sampled_data = data.sample(n=5)\n",
    "pivot_table = data.pivot_table(values='TotalAmount', index='InvoiceDate_Date', aggfunc='sum')\n",
    "reset_data = grouped.reset_index()\n",
    "\n",
    "# Crear tabla auxiliar para merge\n",
    "other_data = pd.DataFrame({\n",
    "    'InvoiceNo': [123456, 654321],\n",
    "    'ExtraInfo': ['Info1', 'Info2']\n",
    "})\n",
    "other_data['InvoiceNo'] = other_data['InvoiceNo'].astype(str)  # Convertir a str\n",
    "\n",
    "# Realizar el merge\n",
    "merged_data = pd.merge(data, other_data, on='InvoiceNo', how='left')\n",
    "print(\"\\nDatos después de realizar un merge:\")\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb5770e",
   "metadata": {},
   "source": [
    "# Estadisticas descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bbda486",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del DataFrame:\n",
      "   Atributo1   Atributo2    Atributo3\n",
      "0  43.708611  484.792314  1031.429186\n",
      "1  95.564288  387.566412  1636.410411\n",
      "2  75.879455  469.749471  1314.355981\n",
      "3  63.879264  447.413675  1508.570691\n",
      "4  24.041678  298.949989  1907.566474\n",
      "\n",
      "Estadísticas de tendencia central:\n",
      "        Atributo1   Atributo2    Atributo3\n",
      "mean    50.133151  247.218791  1478.299917\n",
      "median  49.244388  254.132106  1422.259396\n",
      "\n",
      "Estadísticas de dispersión:\n",
      "        Atributo1     Atributo2     Atributo3\n",
      "std     25.999488    153.420755    297.539299\n",
      "var    675.973381  23537.928095  88529.634678\n",
      "min     11.852604      2.761059   1006.952131\n",
      "max     97.291887    493.443468   1971.782083\n",
      "range   85.439282    490.682410    964.829952\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Crear un diccionario con 50 datos y tres atributos continuos\n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "data_dict = {\n",
    "    \"Atributo1\": np.random.uniform(10, 100, 50),  # Valores entre 10 y 100\n",
    "    \"Atributo2\": np.random.uniform(0, 500, 50),   # Valores entre 0 y 500\n",
    "    \"Atributo3\": np.random.uniform(1000, 2000, 50)  # Valores entre 1000 y 2000\n",
    "}\n",
    "\n",
    "# 2. Transformar el diccionario a un DataFrame de Pandas\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(\"Primeras filas del DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# 3. Obtener estadísticas descriptivas de tendencia central\n",
    "central_tendency = df.agg({\n",
    "    \"Atributo1\": ['mean', 'median'],\n",
    "    \"Atributo2\": ['mean', 'median'],\n",
    "    \"Atributo3\": ['mean', 'median']\n",
    "})\n",
    "print(\"\\nEstadísticas de tendencia central:\")\n",
    "print(central_tendency)\n",
    "\n",
    "# 4. Obtener estadísticas descriptivas de dispersión\n",
    "# Calculamos las estadísticas comunes: std, var, min, max\n",
    "dispersion_stats = df.agg({\n",
    "    \"Atributo1\": ['std', 'var', 'min', 'max'],\n",
    "    \"Atributo2\": ['std', 'var', 'min', 'max'],\n",
    "    \"Atributo3\": ['std', 'var', 'min', 'max']\n",
    "})\n",
    "\n",
    "# Añadir el rango calculado manualmente\n",
    "range_values = pd.Series(df.max() - df.min(), name='range')\n",
    "dispersion_stats = pd.concat([dispersion_stats, range_values.to_frame().T])\n",
    "\n",
    "print(\"\\nEstadísticas de dispersión:\")\n",
    "print(dispersion_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d3bdb",
   "metadata": {},
   "source": [
    "# **Análisis Resumido**\n",
    "\n",
    "## **1. Datos Iniciales**\n",
    "- **Atributo1:** Rango de 11.85 a 97.29.\n",
    "- **Atributo2:** Rango de 2.76 a 493.44.\n",
    "- **Atributo3:** Rango de 1006.95 a 1971.78.\n",
    "\n",
    "## **2. Estadísticas de Tendencia Central**\n",
    "|               | Atributo1 | Atributo2 | Atributo3  |\n",
    "|---------------|-----------|-----------|------------|\n",
    "| **Media**     | 50.13     | 247.22    | 1478.30    |\n",
    "| **Mediana**   | 49.24     | 254.13    | 1422.26    |\n",
    "\n",
    "- Valores distribuidos de manera simétrica en todos los atributos.\n",
    "\n",
    "## **3. Estadísticas de Dispersión**\n",
    "|               | Atributo1 | Atributo2 | Atributo3  |\n",
    "|---------------|-----------|-----------|------------|\n",
    "| **Desv. Est.** | 25.99     | 153.42    | 297.54     |\n",
    "| **Rango**     | 85.44     | 490.68    | 964.83     |\n",
    "\n",
    "- **Atributo1:** Baja dispersión.\n",
    "- **Atributo2 y Atributo3:** Alta variabilidad con amplios rangos.\n",
    "\n",
    "- **Atributo1:** Menor variabilidad y rango moderado.\n",
    "- **Atributo2 y Atributo3:** Mayor dispersión y rangos amplios, representando alta diversidad de valores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b33c255",
   "metadata": {},
   "source": [
    "# Transformación e imputación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83aaa942",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnóstico de valores perdidos en 'ratings_data':\n",
      "UNNAMED: 0     0\n",
      "USER-ID        0\n",
      "ISBN           0\n",
      "BOOK-RATING    0\n",
      "MEANRATING     0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame con promedio de rating por ISBN:\n",
      "         ISBN  MEANRATING\n",
      "0  034545104X    2.933333\n",
      "1  0155061224    2.500000\n",
      "2  0446520802    4.060345\n",
      "3  052165615X    3.000000\n",
      "4  0521795028    6.000000\n",
      "\n",
      "Base de datos consolidada (primeras filas):\n",
      "         ISBN           BOOK-TITLE           BOOK-AUTHOR  YEAR-OF-PUBLICATION  \\\n",
      "0  0195153448  Classical Mythology    Mark P. O. Morford                 2002   \n",
      "1  0002005018         Clara Callan  Richard Bruce Wright                 2001   \n",
      "2  0002005018         Clara Callan  Richard Bruce Wright                 2001   \n",
      "3  0002005018         Clara Callan  Richard Bruce Wright                 2001   \n",
      "4  0002005018         Clara Callan  Richard Bruce Wright                 2001   \n",
      "\n",
      "                 PUBLISHER                                        IMAGE-URL-S  \\\n",
      "0  Oxford University Press  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
      "3    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
      "4    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
      "\n",
      "                                         IMAGE-URL-M  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...   \n",
      "2  http://images.amazon.com/images/P/0002005018.0...   \n",
      "3  http://images.amazon.com/images/P/0002005018.0...   \n",
      "4  http://images.amazon.com/images/P/0002005018.0...   \n",
      "\n",
      "                                         IMAGE-URL-L  UNNAMED: 0  USER-ID  \\\n",
      "0  http://images.amazon.com/images/P/0195153448.0...      9561.0      2.0   \n",
      "1  http://images.amazon.com/images/P/0002005018.0...      9563.0      8.0   \n",
      "2  http://images.amazon.com/images/P/0002005018.0...     43178.0  11400.0   \n",
      "3  http://images.amazon.com/images/P/0002005018.0...     45340.0  11676.0   \n",
      "4  http://images.amazon.com/images/P/0002005018.0...    188244.0  41385.0   \n",
      "\n",
      "   BOOK-RATING  MEANRATING  \n",
      "0          0.0    0.000000  \n",
      "1          5.0    4.928571  \n",
      "2          0.0    4.928571  \n",
      "3          8.0    4.928571  \n",
      "4          0.0    4.928571  \n",
      "\n",
      "Base de datos consolidada exportada como 'consolidated_books_ratings.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1. Cargar las bases de datos con manejo de delimitadores y codificación\n",
    "ratings_data = pd.read_csv(\"ratings_data.csv\", encoding='latin-1')\n",
    "books_data = pd.read_csv(\"books_data.csv\", encoding='latin-1', sep=';')\n",
    "\n",
    "# 2. Normalizar los nombres de las columnas\n",
    "ratings_data.columns = ratings_data.columns.str.strip().str.upper()\n",
    "books_data.columns = books_data.columns.str.strip().str.upper()\n",
    "\n",
    "# 3. Diagnóstico de números perdidos en \"ratings_data\"\n",
    "print(\"Diagnóstico de valores perdidos en 'ratings_data':\")\n",
    "print(ratings_data.isnull().sum())\n",
    "\n",
    "# 4. Imputar valores solo en las columnas numéricas\n",
    "numeric_columns = ratings_data.select_dtypes(include=['number']).columns\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "ratings_data[numeric_columns] = imputer_mean.fit_transform(ratings_data[numeric_columns])\n",
    "\n",
    "# 5. Generar una nueva variable: promedio de rating para cada ISBN\n",
    "ratings_data['MEANRATING'] = ratings_data.groupby('ISBN')['BOOK-RATING'].transform('mean')\n",
    "\n",
    "print(\"\\nDataFrame con promedio de rating por ISBN:\")\n",
    "print(ratings_data[['ISBN', 'MEANRATING']].drop_duplicates().head())\n",
    "\n",
    "# 6. Consolidar las bases de datos utilizando ISBN\n",
    "merged_data = pd.merge(books_data, ratings_data, on='ISBN', how='inner')\n",
    "\n",
    "print(\"\\nBase de datos consolidada (primeras filas):\")\n",
    "print(merged_data.head())\n",
    "\n",
    "# 7. Exportar la base de datos consolidada al directorio actual\n",
    "output_path = \"consolidated_books_ratings.csv\"\n",
    "merged_data.to_csv(output_path, index=False)\n",
    "print(f\"\\nBase de datos consolidada exportada como '{output_path}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
